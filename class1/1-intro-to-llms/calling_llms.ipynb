{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Direct API Call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 'resp_6841a7b9d7ec819ab983dd63eb7fcf860f36b3b04c81ccbd', 'object': 'response', 'created_at': 1749133241, 'status': 'completed', 'background': False, 'error': None, 'incomplete_details': None, 'instructions': None, 'max_output_tokens': None, 'model': 'gpt-4o-2024-08-06', 'output': [{'id': 'msg_6841a7bac6f4819ab2b2a5ed8d3aa8e30f36b3b04c81ccbd', 'type': 'message', 'status': 'completed', 'content': [{'type': 'output_text', 'annotations': [], 'text': 'Under the shimmering light of the crescent moon, Luna the unicorn gently soared through the starry sky, leaving a trail of sparkling dreams for children below.'}], 'role': 'assistant'}], 'parallel_tool_calls': True, 'previous_response_id': None, 'reasoning': {'effort': None, 'summary': None}, 'service_tier': 'default', 'store': True, 'temperature': 1.0, 'text': {'format': {'type': 'text'}}, 'tool_choice': 'auto', 'tools': [], 'top_p': 1.0, 'truncation': 'disabled', 'usage': {'input_tokens': 18, 'input_tokens_details': {'cached_tokens': 0}, 'output_tokens': 32, 'output_tokens_details': {'reasoning_tokens': 0}, 'total_tokens': 50}, 'user': None, 'metadata': {}}\n"
     ]
    }
   ],
   "source": [
    "# curl \"https://api.openai.com/v1/responses\" \\\n",
    "#     -H \"Content-Type: application/json\" \\\n",
    "#     -H \"Authorization: Bearer $OPENAI_API_KEY\" \\\n",
    "#     -d '{\n",
    "#         \"model\": \"gpt-4.1\",\n",
    "#         \"input\": \"Write a one-sentence bedtime story about a unicorn.\"\n",
    "#       }'\n",
    "\n",
    "import os\n",
    "import requests\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "def call_llm(model: str, input: str):\n",
    "    url = \"https://api.openai.com/v1/responses\"\n",
    "    headers = {\n",
    "        \"Content-Type\": \"application/json\",\n",
    "        \"Authorization\": f\"Bearer {os.getenv('OPENAI_API_KEY')}\"\n",
    "    }\n",
    "    data = {\n",
    "        \"model\": model,\n",
    "        \"input\": input\n",
    "    }\n",
    "    response = requests.post(url, headers=headers, json=data)\n",
    "    return response.json()\n",
    "\n",
    "response = call_llm(\"gpt-4o\", \"Write a one-sentence bedtime story about a unicorn.\")\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': 'msg_6841a7bac6f4819ab2b2a5ed8d3aa8e30f36b3b04c81ccbd',\n",
       "  'type': 'message',\n",
       "  'status': 'completed',\n",
       "  'content': [{'type': 'output_text',\n",
       "    'annotations': [],\n",
       "    'text': 'Under the shimmering light of the crescent moon, Luna the unicorn gently soared through the starry sky, leaving a trail of sparkling dreams for children below.'}],\n",
       "  'role': 'assistant'}]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response[\"output\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OpenAI SDK Call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response(id='resp_6841a852f6cc8199b0e2e77e1d7688db089bcd159c6945a6', created_at=1749133394.0, error=None, incomplete_details=None, instructions=None, metadata={}, model='gpt-4.1-2025-04-14', object='response', output=[ResponseOutputMessage(id='msg_6841a853b76c8199973a002ddbc09130089bcd159c6945a6', content=[ResponseOutputText(annotations=[], text='In a quiet, moonlit meadow, a gentle unicorn named Luna discovered a silver star fallen from the sky. She touched it with her shimmering horn, and it began to glow, lighting up the whole forest with a magical warmth. As Luna drifted off to sleep, the forest creatures snuggled close, dreaming sweet dreams under the star’s gentle light.', type='output_text', logprobs=None)], role='assistant', status='completed', type='message')], parallel_tool_calls=True, temperature=1.0, tool_choice='auto', tools=[], top_p=1.0, background=False, max_output_tokens=None, previous_response_id=None, reasoning=Reasoning(effort=None, generate_summary=None, summary=None), service_tier='default', status='completed', text=ResponseTextConfig(format=ResponseFormatText(type='text')), truncation='disabled', usage=ResponseUsage(input_tokens=18, input_tokens_details=InputTokensDetails(cached_tokens=0), output_tokens=73, output_tokens_details=OutputTokensDetails(reasoning_tokens=0), total_tokens=91), user=None, store=True)\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "response = client.responses.create(\n",
    "  model=\"gpt-4.1\",\n",
    "  input=\"Tell me a three sentence bedtime story about a unicorn.\"\n",
    ")\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'In a quiet, moonlit meadow, a gentle unicorn named Luna discovered a silver star fallen from the sky. She touched it with her shimmering horn, and it began to glow, lighting up the whole forest with a magical warmth. As Luna drifted off to sleep, the forest creatures snuggled close, dreaming sweet dreams under the star’s gentle light.'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.output[0].content[0].text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LangChain Call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Você perguntou qual é a capital de Cuba. Eu não respondi corretamente. A capital de Cuba é Havana. Desculpe pelo erro.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 28, 'prompt_tokens': 36, 'total_tokens': 64, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_a288987b44', 'id': 'chatcmpl-Bf5sFnrapo3AvhrLvakHOC5T41xsD', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--545c6acf-c586-46a3-9189-a5e3d9323780-0', usage_metadata={'input_tokens': 36, 'output_tokens': 28, 'total_tokens': 64, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import HumanMessage, AIMessage, BaseMessage\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o\")\n",
    "\n",
    "response = llm.invoke(\"Tell me a three sentence bedtime story about a unicorn.\")\n",
    "\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='The sum of 1 and 2 is 3.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 12, 'prompt_tokens': 18, 'total_tokens': 30, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_07871e2ad8', 'id': 'chatcmpl-Bf5ySAVGVLrUe3YRqAcxtDCCGhvOm', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--a5b7b88a-d93d-4610-895a-5dfad4f90cae-0', usage_metadata={'input_tokens': 18, 'output_tokens': 12, 'total_tokens': 30, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(\"What is the sum of 1 and 2?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_wcoRZZwQCi7WSmr1nIJ6LW51', 'function': {'arguments': '{\"a\":1,\"b\":2}', 'name': 'add'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 17, 'prompt_tokens': 80, 'total_tokens': 97, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_a288987b44', 'id': 'chatcmpl-Bf5ydaOmFleyQ79jrxTN96uAzf7k5', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--5d84a166-341c-42f9-b2e6-7f3a31eb1141-0', tool_calls=[{'name': 'add', 'args': {'a': 1, 'b': 2}, 'id': 'call_wcoRZZwQCi7WSmr1nIJ6LW51', 'type': 'tool_call'}], usage_metadata={'input_tokens': 80, 'output_tokens': 17, 'total_tokens': 97, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def add(a:int, b:int) -> int:\n",
    "    \"\"\"Function that take two integers a and b and return the sum of them.\n",
    "    Args:\n",
    "        a: The first integer.\n",
    "        b: The second integer.\n",
    "        \n",
    "    Returns:\n",
    "        The sum of a and b.\n",
    "    \"\"\"\n",
    "    return a + b\n",
    "\n",
    "llm_with_tools = llm.bind_tools([add])\n",
    "\n",
    "response = llm_with_tools.invoke(\"What is the sum of 1 and 2?\")\n",
    "\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
